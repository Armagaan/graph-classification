{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import dgl\n",
    "import torch\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from gcn import GCNGraph\n",
    "from utils.preprocessing.mutag_preprocessing_0 \\\n",
    "    import mutag_preprocessing_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = \"/home/shade/code/github/graph-classification/data/Mutagenicity/raw\"\n",
    "dataset = mutag_preprocessing_0(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['idx_train', 'idx_val', 'idx_test'])\n"
     ]
    }
   ],
   "source": [
    "with open(\"../../../data/Mutagenicity/processed/index.pkl\", \"rb\") as file:\n",
    "    index = pickle.load(file)\n",
    "print(index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tuple(dataset[idx] for idx in index['idx_train'])\n",
    "val_dataset = tuple(dataset[idx] for idx in index['idx_val'])\n",
    "test_dataset = tuple(dataset[idx] for idx in index['idx_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150 282 1132\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCNGraph(\n",
      "  (conv1): GraphConvLayer()\n",
      "  (conv2): GraphConvLayer()\n",
      "  (conv3): GraphConvLayer()\n",
      "  (dense1): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (dense2): Linear(in_features=16, out_features=8, bias=True)\n",
      "  (dense3): Linear(in_features=8, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = GCNGraph(\n",
    "    in_feats=dataset.graphs[0].ndata['feat'].size(1),\n",
    "    h_feats=128\n",
    ")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in train_dataset: # Iterate in batches over the training dataset.\n",
    "        graph, label = data\n",
    "        out = model(\n",
    "            graph,\n",
    "            graph.ndata['feat'].float(),\n",
    "            graph.edata['weight'].float()\n",
    "        ).squeeze()\n",
    "        loss = criterion(out, label.float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "def test(dataset):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in dataset: # Iterate in batches over the training/test dataset.\n",
    "        graph, label = data\n",
    "        out = model(\n",
    "            graph,\n",
    "            graph.ndata['feat'].float(),\n",
    "            graph.edata['weight'].float()\n",
    "        ).squeeze()\n",
    "        pred = out.round()\n",
    "\n",
    "        correct += int((pred == label).sum())\n",
    "    return correct / len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.7913, Val Acc: 0.8652\n",
      "Checkpoint saved!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13742/1699487997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_test_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_13742/276123271.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         ).squeeze()\n\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cfsqr/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cfsqr/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "best_test_acc = 0.0\n",
    "for epoch in range(1, 201):\n",
    "    train()\n",
    "    train_acc = test(train_dataset)\n",
    "    val_acc = test(val_dataset)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
    "    if val_acc >= best_test_acc:\n",
    "        best_test_acc = val_acc\n",
    "        best_model_params = model.state_dict()\n",
    "        print(\"Checkpoint saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training fails becuase we have not batched the data. We are supplying one graph at a time for training, which is not helping the model learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight   : torch.Size([10, 128])\n",
      "conv1.bias     : torch.Size([128])\n",
      "conv2.weight   : torch.Size([128, 128])\n",
      "conv2.bias     : torch.Size([128])\n",
      "conv3.weight   : torch.Size([128, 128])\n",
      "conv3.bias     : torch.Size([128])\n",
      "dense1.weight  : torch.Size([16, 128])\n",
      "dense1.bias    : torch.Size([16])\n",
      "dense2.weight  : torch.Size([8, 16])\n",
      "dense2.bias    : torch.Size([8])\n",
      "dense3.weight  : torch.Size([1, 8])\n",
      "dense3.bias    : torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "state_dict = torch.load(\"new_mutag_weights.pt\")\n",
    "for key, val in state_dict.items():\n",
    "    print(f\"{key:<15}: {val.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCNGraph(\n",
       "  (conv1): GraphConvLayer()\n",
       "  (conv2): GraphConvLayer()\n",
       "  (conv3): GraphConvLayer()\n",
       "  (dense1): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (dense2): Linear(in_features=16, out_features=8, bias=True)\n",
       "  (dense3): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(state_dict)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 98.23 %\n"
     ]
    }
   ],
   "source": [
    "test_acc = test(test_dataset)\n",
    "print(f\"Test accuracy: {100 * test_acc:.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0., 1.]), tensor([910, 240]))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list()\n",
    "for data in train_dataset:\n",
    "    labels.append(int(data[1]))\n",
    "torch.Tensor(labels).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shade/downloads/masked_adj.pkl\", \"rb\") as file:\n",
    "    masked_adj_49 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_adj_49.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9763]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\n",
    "    dataset.graphs[49],\n",
    "    dataset.graphs[49].ndata['feat'].float(),\n",
    "    masked_adj_49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\n",
    "    dataset.graphs[49],\n",
    "    dataset.graphs[49].ndata['feat'].float(),\n",
    "    dataset.graphs[49].edata['weight']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.graphs[49].edata['weight'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1370, -0.0764, -0.4804, -0.1968, -0.0904, -0.1928, -0.5255, -0.3249,\n",
       "        -0.1876, -0.3404, -0.1368,  0.3557, -0.2448, -0.2277, -0.1359, -0.0202,\n",
       "        -0.3081, -0.5144, -0.2919, -0.0261, -0.4159, -0.0839, -0.2636, -0.6694,\n",
       "        -0.4344, -0.1721, -0.1353, -0.1064, -0.4041, -0.1016, -0.3166, -0.4336,\n",
       "         0.0222, -0.9834, -1.0611, -0.2956, -0.3851, -0.3787, -0.2058, -0.2987,\n",
       "        -0.3875, -0.0783, -0.0639, -0.2598, -0.4567, -0.2782, -0.4126, -0.2928,\n",
       "        -0.3130, -0.0430, -0.3958, -0.2801, -0.0516, -0.0580, -0.0160, -1.0119,\n",
       "        -0.0907, -0.1717, -0.0297, -0.3054, -0.6030, -0.3072, -0.4305, -0.1296,\n",
       "        -0.0167, -0.1503, -0.1967, -0.1303,  0.0871, -0.0463, -0.0833, -0.5474,\n",
       "        -0.1450,  0.4611, -0.4763, -0.0014, -0.9524, -0.0916, -0.5872, -0.1042,\n",
       "        -0.3744, -0.0876, -0.8267, -0.3524, -0.1421, -0.0959, -0.1860, -0.1253,\n",
       "         0.1755, -0.3871, -0.3049, -0.0716, -0.0856, -0.2816, -0.0456,  0.4822,\n",
       "        -0.1386, -0.1239, -0.2325, -0.1969, -0.1890, -0.0050, -0.5033, -0.1162,\n",
       "        -0.0229, -0.1569, -1.1568, -0.1472, -0.2263, -0.2258, -0.4495, -0.2433,\n",
       "        -0.1713, -0.3093, -0.0458, -0.0401, -0.4845, -0.4697, -0.0801,  0.1072,\n",
       "        -0.4081, -0.1235, -0.1510, -0.1577, -0.1313, -0.0795, -0.2567, -0.4099])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict['conv1.weight'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.373626373626372"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 240/910"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cfsqr')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7d096456d4adc4d0d94f2f60b5cf993aa1d5a534cad4a79ff1a4d3ab1294b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
